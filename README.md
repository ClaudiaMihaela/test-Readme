# Analiza Politicilor de ÃnvÄƒÈ›are Ã®n Federated Learning (FL) prin ReÈ›ele Neurale È™i Fictitious Play

Acest proiect implementeazÄƒ un cadru de simulare È™i analizÄƒ pentru adoptarea strategiilor Ã®n sistemele de **Federated Learning (FL)**. Codul utilizeazÄƒ tehnici de reÈ›ele neurale pentru Ã®nvÄƒÈ›area politicilor (*Policy Learning*) È™i algoritmi din teoria jocurilor (**Fictitious Play**) pentru a prezice echilibrul Nash Ã®n diferite scenarii de adoptare a tehnologiei.

## ğŸ“‹ Cuprins
1. Descriere GeneralÄƒ
2. Scenarii Analizate
3. Componente Software
4. Instalare È™i Utilizare
5. Interpretarea Rezultatelor

---

## ğŸš€ Descriere GeneralÄƒ
Codul este structurat Ã®n douÄƒ secÈ›iuni majore de analizÄƒ computaÈ›ionalÄƒ:

1.  **Neural Network Policy Learning:** AntreneazÄƒ o reÈ›ea de tip *feed-forward* pentru a aproxima strategia optimÄƒ a unui nod dintr-un sistem FL, bazÃ¢ndu-se pe matrice de recompense (*payoff matrices*).
2.  **Dinamica ÃnvÄƒÈ›Äƒrii È™i Stabilitate:** UtilizeazÄƒ algoritmul *Fictitious Play* pentru a observa cum converg strategiile jucÄƒtorilor Ã®n timp spre un punct de echilibru È™i analizeazÄƒ senzitivitatea acestui echilibru Ã®n funcÈ›ie de beneficiile de acurateÈ›e.



[Image of neural network architecture diagram]


---

## ğŸ“Š Scenarii Analizate
Sunt evaluate patru contexte distincte, reprezentate prin matrice de utilitate, pentru a observa comportamentul agenÈ›ilor:

* **Scenariul (a) - Early Adopters (EA):** Beneficii ridicate pentru adoptarea timpurie.
* **Scenariul (b) - Late Adopters (LA):** Recompense optimizate pentru tranziÈ›ia Ã®ntÃ¢rziatÄƒ.
* **Scenariul (c) - RezistenÈ›Äƒ RidicatÄƒ:** Utilitate scÄƒzutÄƒ pentru cooperare, simulÃ¢nd un mediu sceptic sau costuri mari de participare.
* **Scenariul (d) - PopulaÈ›ie EchilibratÄƒ:** Testarea stabilitÄƒÈ›ii Ã®ntr-un mediu cu beneficii reduse.

---

## ğŸ› ï¸ Componente Software

### 1. Neural Network Policy Learning
* **ArhitecturÄƒ:** MLP (Multi-Layer Perceptron) cu douÄƒ straturi ascunse de dimensiuni `[10 5]`.
* **Intrare (Input):** DistribuÈ›ii aleatorii de probabilitate ale strategiilor din reÈ›ea.
* **IeÈ™ire (Output):** Clasificarea strategiei optime (EA, LA sau R).
* **Antrenare:** FoloseÈ™te algoritmul Levenberg-Marquardt pentru minimizarea MSE (Mean Squared Error).

### 2. Fictitious Play (Teoria Jocurilor)
* ImplementeazÄƒ un model de Ã®nvÄƒÈ›are iterativÄƒ unde fiecare jucÄƒtor Ã®È™i alege cea mai bunÄƒ replicÄƒ (*Best Response*) bazÃ¢ndu-se pe frecvenÈ›a acÈ›iunilor trecute ale adversarilor.
* IdentificÄƒ numeric punctele de **Echilibru Nash (NE)** pentru fiecare scenariu.



### 3. Analiza de Senzitivitate
* EvalueazÄƒ robusteÈ›ea echilibrului pentru strategia "Late Adopter".
* VariazÄƒ parametrul de beneficiu ($b$) pentru a identifica pragul de stabilitate al sistemului.

---

## ğŸ’» Instalare È™i Utilizare
1.  AsiguraÈ›i-vÄƒ cÄƒ aveÈ›i instalat **MATLAB** (versiune recomandatÄƒ R2021a sau mai recentÄƒ).
2.  NecesitÄƒ **Deep Learning Toolbox** pentru funcÈ›iile `feedforwardnet` È™i `train`.
3.  CopiaÈ›i codul Ã®ntr-un script de tip `.m` (ex: `analiza_FL.m`).
4.  RulaÈ›i scriptul. Acesta va genera automat douÄƒ ferestre grafice maximizate cu rezultatele analizei.

---

## ğŸ“ˆ Interpretarea Rezultatelor

| Grafic | ExplicaÈ›ie |
| :--- | :--- |
| **Training Loss** | IndicÄƒ eroarea de aproximare a reÈ›elei. O curbÄƒ descendentÄƒ confirmÄƒ faptul cÄƒ NN a Ã®nvÄƒÈ›at corect matricea de payoff. |
| **Politica ÃnvÄƒÈ›atÄƒ** | ReprezintÄƒ probabilitatea ca un agent sÄƒ aleagÄƒ o anumitÄƒ strategie FL Ã®n funcÈ›ie de contextul Ã®nvÄƒÈ›at. |
| **Dinamica ÃnvÄƒÈ›Äƒrii** | IlustreazÄƒ convergenÈ›a strategiilor spre echilibru pe parcursul celor 1000 de iteraÈ›ii. |
| **Stabilitate LA** | AratÄƒ intervalul de parametri Ã®n care strategia "Late Adopter" rÄƒmÃ¢ne cea mai bunÄƒ opÈ›iune. |

---

## ğŸ“ Note Tehnice
* Normalizarea datelor se face prin `X ./ sum(X, 2)` pentru a asigura suma probabilitÄƒÈ›ilor egalÄƒ cu 1.
* S-a introdus un factor de zgomot (`0.08 * rand`) Ã®n etichetarea datelor pentru a permite vizualizarea progresului pierderii (*loss*) Ã®n timpul antrenÄƒrii reÈ›elei.
